{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAR-Preprocessing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY_Pl0khOtkt",
        "colab_type": "text"
      },
      "source": [
        "# Human Activity Recognition using Inertial sensors and Neural Networks\n",
        "\n",
        "Elia Bonetto, Filippo Rigotto. \n",
        "\n",
        "Deptartment of Information Engineering, University of Padova, Italy.\n",
        "\n",
        "Human Data Analytics, a.y. 2018/2019\n",
        "\n",
        "## Part 1 - Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeKKPUPPF1PO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image, clear_output\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "clear_output()\n",
        "!ls /content/drive/My\\ Drive/hda-project\n",
        "os.chdir(\"/content/drive/My Drive/hda-project\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_j884TpGNrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import logging\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.io\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.precision',3)\n",
        "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "mpl.rcParams['figure.figsize'] = (16,10)\n",
        "mpl.rcParams['axes.grid'] = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LZs68Tz7_mG",
        "colab_type": "text"
      },
      "source": [
        "Here we start from the [original datasets](https://www.dlr.de/kn/desktopdefault.aspx/tabid-8500/14564_read-36508/) and process data items to have the final dataset all our net models will work on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l08TcOt9h2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets = [\n",
        "    'dataset/ARS_DLR_DataSet.mat',\n",
        "    'dataset/ARS_DLR_DataSet_V2.mat',\n",
        "    'dataset/ARS_DLR_Benchmark_Data_Set.mat'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfOGIDTkDXgQ",
        "colab_type": "text"
      },
      "source": [
        "We reduce the labels to detect from the original 17 down to 8.\n",
        "\n",
        "Furthermore, we don't detect transitions, so the final number of labels we work with is 7."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovSOpId9vap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = ['RUNNING', 'WALKING', 'JUMPING','STNDING','SITTING', 'XLYINGX', 'FALLING',\n",
        "    'WALKUPS', 'WALKDWS',\n",
        "    'JUMPVRT', 'JUMPFWD', 'JUMPBCK', \n",
        "    'TRANSUP', 'TRANSDW', 'TRNSACC', 'TRNSDCC', 'TRANSIT'\n",
        "]\n",
        "\n",
        "map_encode = { label:i for i,label in enumerate(labels) }\n",
        "\n",
        "map_encode_8 = {\n",
        "    0:0,   1:1,  2:2,  3:3,  4:4,  5:5,  6:6,\n",
        "    7:1,   8:1, # walking up and downstairs = walking\n",
        "    9:2,  10:2, 11:2, # jumping in place, forward and backward = jumping\n",
        "    12:7, 13:7, 14:7, 15:7, 16:7 # all transitions\n",
        "}\n",
        "\n",
        "map_decode_8 = {\n",
        "    0: 'running',\n",
        "    1: 'walking',\n",
        "    2: 'jumping',\n",
        "    3: 'standing',\n",
        "    4: 'sitting',\n",
        "    5: 'lying',\n",
        "    6: 'falling',\n",
        "    7: 'transition'\n",
        "}\n",
        "\n",
        "num_classes = len(map_encode)\n",
        "print(\"Num original classes: {}\".format(num_classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB4FskfwEOlL",
        "colab_type": "text"
      },
      "source": [
        "The dataset provides the list of labels (\"activities\") for each segment of tracked data, along with index bounds for each item of the list. We flat this struct to a single list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Z9H1Tv-W2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten_labels(labels, bounds):\n",
        "    \"\"\"Builds a single labels array from labels and bounds.\"\"\"\n",
        "    start = bounds[0::2]-1 # even positions\n",
        "    stop  = bounds[1::2]   # -1: numbering starts from 1\n",
        "\n",
        "    # start is included, stop is excluded\n",
        "    # TODO WRITE ON REPORT HOLES AND MISTIMING!!!!!!\n",
        "    res = np.ones(bounds[-1], dtype=np.uint8) * map_encode['TRANSIT']\n",
        "    for i, lab in enumerate(labels):\n",
        "      if i+1<len(stop):\n",
        "        if stop[i] > start[i+1]+1:\n",
        "          start[i+1] = stop[i]\n",
        "      res[start[i] : stop[i]] = lab\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVcomuAZEi2r",
        "colab_type": "text"
      },
      "source": [
        "The dataset contains IMU measurements referred to the sensor frame, but also provides the attitude/cosine matrix to express the measurements w.r.t. the body frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsd0NVgF-xHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_body_frame(imu_data, attitude_matrix):\n",
        "    \"\"\"Converts sensor frames in a data item to body frames through the attitude matrix.\"\"\"\n",
        "    C = attitude_matrix[1:].reshape(3,3).T\n",
        "\n",
        "    result = imu_data.copy()\n",
        "    result[1:4]  = np.dot(C, imu_data[1:4].T)  # acc\n",
        "    result[4:7]  = np.dot(C, imu_data[4:7].T)  # gyro\n",
        "    result[7:10] = np.dot(C, imu_data[7:10].T) # mag\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Ladk5mE9EP",
        "colab_type": "text"
      },
      "source": [
        "For each test in a dataset, we extract the relevant data, and then flat the labels to a single long list.\n",
        "\n",
        "The rest of the processing is postponed to operate on the full dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke3Npi6a_u0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summacumlaude = 0\n",
        "def process_single_test(dataset, key, summacumlaude):\n",
        "    imu_data, attitude_matrices, activities, activities_bounds = dataset[key][0]\n",
        "\n",
        "    # throwing away useless nested arrays\n",
        "    activities = np.array([ act[0] for act in activities[0] ])\n",
        "    activities_bounds = activities_bounds[0]\n",
        "    \n",
        "    # integrity checks on time and length\n",
        "    assert([ imu_data[i][0] == attitude_matrices[i][0] for i in range(len(imu_data)) ])\n",
        "    assert(len(activities_bounds) == 2*len(activities))\n",
        "\n",
        "    # change labels to int numbers\n",
        "    activities = np.array([ map_encode[a] for a in activities ])\n",
        "\n",
        "    # get a single array of labels instead of labels + bounds\n",
        "    activities_flat = flatten_labels(activities, activities_bounds)\n",
        "    #print(len(activities_flat[activities_flat == 0]))\n",
        "    assert(len(imu_data) == len(activities_flat))\n",
        "\n",
        "    return imu_data, attitude_matrices, activities_flat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLbeEpQXFdtH",
        "colab_type": "text"
      },
      "source": [
        "We use numpy arrays to store all the collected data from every test in each dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKlBfX4BBvHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imu_sensor = np.empty((0,10))\n",
        "attitude_mat = np.empty((0,10))\n",
        "activities = np.empty((0,1), dtype=np.uint8)\n",
        "\n",
        "# loop datasets\n",
        "for ds in datasets:\n",
        "    dataset = scipy.io.loadmat(ds)\n",
        "    keys = [ k for k in dataset if '__' not in k ]\n",
        "    # loop keys=tests\n",
        "    for test in keys:\n",
        "        print('Loading {}:'.format(test).ljust(52,' '), end='')\n",
        "        imu, mat, act = process_single_test(dataset, test, summacumlaude)\n",
        "        imu_sensor = np.append(imu_sensor, imu, axis=0)\n",
        "        attitude_mat = np.append(attitude_mat, mat, axis=0)\n",
        "        activities = np.append(activities, act)\n",
        "        \n",
        "        print('{} elements'.format(imu.shape[0]).rjust(15,' '))\n",
        "\n",
        "assert(imu_sensor.shape==attitude_mat.shape)\n",
        "num_data = imu_sensor.shape[0]\n",
        "clear_output()\n",
        "print('Read {} records'.format(num_data))\n",
        "print('IMU data shape:   {}'.format(imu_sensor.shape))\n",
        "print('Attitudes shape:  {}'.format(attitude_mat.shape))\n",
        "print('Activities shape: {}'.format(activities.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt2TD-DUTvpi",
        "colab_type": "text"
      },
      "source": [
        "We save this checkpoint, even if we don't use it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unmK9NtcUAwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with h5py.File('dataset/ARS-raw.h5','w') as h5f:\n",
        "    h5f.create_dataset('imu_sensor', data=imu_sensor)\n",
        "    h5f.create_dataset('attitudes',  data=attitude_mat)\n",
        "    h5f.create_dataset('activities', data=activities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or5FNfvCUMik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# optional reload if messing up below\n",
        "#with h5py.File('dataset/ARS-raw.h5','r') as h5f:\n",
        "#    imu_sensor = h5f['imu_sensor'][:]\n",
        "#    attitude_mat = h5f['attitudes'][:]\n",
        "#    activities = h5f['activities'][:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXeJ_ymQLYvn",
        "colab_type": "text"
      },
      "source": [
        "Checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coFWmHUDLdJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "act,cnt = np.unique(activities, return_counts=True)\n",
        "cnt_sum = sum(cnt)\n",
        "cnt = cnt / 100 / 60 # 100 Hz, 60 seconds\n",
        "act = np.array([labels[a].lower() for a in act])\n",
        "\n",
        "act = np.append(act,'total')\n",
        "cnt = np.append(cnt, cnt_sum)\n",
        "\n",
        "df = pd.DataFrame(np.array([act,cnt]).T, columns=['Activity','Time (min)'])\n",
        "df.index = [''] * len(df) # blank index\n",
        "display(df)\n",
        "\n",
        "#TODO other if needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_-gvcNBHKkd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "More processing:\n",
        "- reduce the number of tracked activities to 8\n",
        "- removal of items labelled as transitions\n",
        "- conversion of measurements to the body frame\n",
        "- removal of time column (in both measurements and attitude matrixes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27hU5N27eRXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remap activities\n",
        "print('Old labels: {}'.format(np.unique(activities)))\n",
        "activities = np.array([ map_encode_8[act] for act in activities])\n",
        "print('New labels: {}'.format(np.unique(activities)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKtvqG1aHLzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove transitions\n",
        "transit_label = map_encode_8[map_encode['TRANSIT']]\n",
        "transit_number = sum(activities == transit_label)\n",
        "print('Transit label is {}, found {} elements'.format(transit_label, transit_number))\n",
        "\n",
        "num_data = len(imu_sensor)\n",
        "print('Old num data: {}'.format(num_data))\n",
        "imu_sensor = imu_sensor[activities != transit_label]\n",
        "assert(imu_sensor.shape[0] == num_data-transit_number)\n",
        "attitude_mat = attitude_mat[activities != transit_label]\n",
        "assert(attitude_mat.shape[0] == num_data-transit_number)\n",
        "activities = activities[activities != transit_label]\n",
        "assert(activities.shape[0] == num_data-transit_number)\n",
        "\n",
        "num_data = len(imu_sensor)\n",
        "print('New num data: {}'.format(num_data))\n",
        "\n",
        "num_labels = len(np.unique(activities))\n",
        "print('New num labels: {}'.format(num_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9ngv9Uwd8jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert from sensor frame to body frame\n",
        "imu_body = imu_sensor.copy()\n",
        "for i, imu in enumerate(imu_sensor):\n",
        "    imu_body[i] = convert_body_frame(imu, attitude_mat[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gkhe3BMd-Se",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove time column from data\n",
        "imu_sensor = imu_sensor[:,1:]\n",
        "imu_body = imu_body[:,1:]\n",
        "attitude_mat = attitude_mat[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGxV0TGtLgYm",
        "colab_type": "text"
      },
      "source": [
        "Checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlBD0dxyLhqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "act,cnt = np.unique(activities, return_counts=True)\n",
        "cnt_sum = sum(cnt)\n",
        "cnt = cnt / 100 / 60\n",
        "act = np.array([map_decode_8[a] for a in act])\n",
        "\n",
        "act = np.append(act,'total')\n",
        "cnt = np.append(cnt, cnt_sum)\n",
        "\n",
        "df = pd.DataFrame(np.array([act,cnt]).T, columns=['Activity','Time (min)'])\n",
        "df.index = [''] * len(df)\n",
        "display(df)\n",
        "\n",
        "#TODO other if needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BJbsBq-MlC_",
        "colab_type": "text"
      },
      "source": [
        "Framing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGXChg8uNqxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms44alUwMmYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window_len = 128\n",
        "stride_len = window_len / 2\n",
        "x, y = [], []\n",
        "\n",
        "for activity in np.unique(activities):\n",
        "  tmp = imu_sensor[activities == activity]\n",
        "  if len(imu_sensor[activities == activity]) % stride_len != 0:\n",
        "    tmp = np.append(tmp,[[0]*9]*int((math.floor((len(tmp)-window_len)/stride_len) + 1)*stride_len-len(tmp)+window_len), axis = 0)\n",
        "    #exluding padded arrays\n",
        "    x.extend([tmp[i:i+int(window_len)] for i in range(0,len(tmp)-window_len,int(stride_len))])\n",
        "    y.extend([activity for i in range(0,len(tmp)-window_len,int(stride_len))])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfOCe5dmi-Xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBx9uu_TgbT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x.shape)\n",
        "print(len(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQjCrfvvQkut",
        "colab_type": "text"
      },
      "source": [
        "Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kD60s-HQmUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XpW5WzsQodc",
        "colab_type": "text"
      },
      "source": [
        "Checks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqjGncLWQplM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF8yqFQ7L7_p",
        "colab_type": "text"
      },
      "source": [
        "We now save the entire dataset, even if we won't use this directly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m88YG2NRL7Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with h5py.File('dataset/ARS-full.h5','w') as h5f:\n",
        "    h5f.create_dataset('imu_sens', data=imu_sensor)\n",
        "    h5f.create_dataset('imu_body', data=imu_body)\n",
        "    h5f.create_dataset('attitudes', data=attitude_mat)\n",
        "    h5f.create_dataset('activities', data=activities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb9k8fPwLoCC",
        "colab_type": "text"
      },
      "source": [
        "We pre-compute and save a 80/20 train/test split of the dataset, using body-referenced data and corresponding labels. \n",
        "\n",
        "This is the final version we will use for training all our models.\n",
        "\n",
        "`random_state` is the seed of the PRNG."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXz4oqm2UpNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = \\\n",
        "    train_test_split(imu_body, activities, test_size=0.2, random_state=1)\n",
        "\n",
        "print(\"IMU shape:     \" + str(imu_body.shape))\n",
        "print(\"Labels shape:  \" + str(activities.shape))\n",
        "print(\"X_train shape: \" + str(X_train.shape))\n",
        "print(\"Y_train shape: \" + str(Y_train.shape))\n",
        "print(\"X_test shape:  \" + str(X_test.shape))\n",
        "print(\"Y_test shape:  \" + str(Y_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p87LKo2sNo_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with h5py.File('dataset/ARS-train-test.h5','w') as h5f:\n",
        "    h5f.create_dataset('X_train', data=X_train)\n",
        "    h5f.create_dataset('X_test',  data=X_test)\n",
        "    h5f.create_dataset('Y_train', data=Y_train)\n",
        "    h5f.create_dataset('Y_test',  data=Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-6baz3RnoDo",
        "colab_type": "text"
      },
      "source": [
        "**Done**. Move to part 2 to see DL in action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncBaXDbos436",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git status"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5auHrfHQVi83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git add HAR-Preprocessing.ipynb;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E_ym-T1VqSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git commit -m \"Framing\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Jxr47i5VuZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git config --global user.name 'Elia Bonetto'; git config user.email 'eliabntt94@gmail.com'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7IUJptgV7Kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git push origin master"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
