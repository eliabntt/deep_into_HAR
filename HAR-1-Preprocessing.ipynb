{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAR-1-Preprocessing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY_Pl0khOtkt",
        "colab_type": "text"
      },
      "source": [
        "# Going deep into Human Activity Recognition\n",
        "\n",
        "**Elia Bonetto, Filippo Rigotto.**\n",
        "\n",
        "Department of Information Engineering, University of Padova, Italy.\n",
        "\n",
        "Human Data Analytics, a.y. 2018/2019\n",
        "\n",
        "## Part 1 - Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeKKPUPPF1PO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image, clear_output\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "clear_output()\n",
        "os.chdir(\"/content/drive/My Drive/hda-project\")\n",
        "#!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_j884TpGNrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transforms3d\n",
        "clear_output()\n",
        "\n",
        "from collections import Counter\n",
        "import json\n",
        "import logging\n",
        "import math\n",
        "import random\n",
        "\n",
        "from transforms3d.axangles import axangle2mat\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.io\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.precision',3)\n",
        "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
        "\n",
        "from imblearn.over_sampling import ADASYN \n",
        "from sklearn.model_selection import train_test_split\n",
        "import skimage\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rcParams['figure.figsize'] = (16,10)\n",
        "mpl.rcParams['axes.grid'] = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LZs68Tz7_mG",
        "colab_type": "text"
      },
      "source": [
        "## Loading\n",
        "\n",
        "Let's start from the [original datasets](https://www.dlr.de/kn/desktopdefault.aspx/tabid-8500/14564_read-36508/) provided as MATLAB `mat` files and process data items to have the final dataset all the network models will work on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l08TcOt9h2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets = [\n",
        "    'dataset/ARS_DLR_DataSet.mat',\n",
        "    'dataset/ARS_DLR_DataSet_V2.mat',\n",
        "    'dataset/ARS_DLR_Benchmark_Data_Set.mat'\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfOGIDTkDXgQ",
        "colab_type": "text"
      },
      "source": [
        "Classes  to detect are reduced from the original 17 down to 8.\n",
        "\n",
        "Furthermore, transitions will not be detected, so the final number of used labels is 7."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovSOpId9vap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = [\n",
        "    'RUNNING', 'WALKING', 'JUMPING','STNDING','SITTING', 'XLYINGX', 'FALLING',\n",
        "    'WALKUPS', 'WALKDWS',\n",
        "    'JUMPVRT', 'JUMPFWD', 'JUMPBCK', \n",
        "    'TRANSUP', 'TRANSDW', 'TRNSACC', 'TRNSDCC', 'TRANSIT'\n",
        "]\n",
        "\n",
        "# full map for all 17 classes\n",
        "map_encode = { label:i for i,label in enumerate(labels) }\n",
        "\n",
        "# map to squeeze down to 8 classes\n",
        "map_encode_8 = {\n",
        "    0:0,   1:1,  2:2,  3:3,  4:4,  5:5,  6:6, # untouched\n",
        "    7:1,   8:1,                  # walking up and downstairs = walking\n",
        "    9:2,  10:2, 11:2,            # jumping in place, forward and backward = jumping\n",
        "    12:7, 13:7, 14:7, 15:7, 16:7 # all transitions\n",
        "}\n",
        "\n",
        "# useful for plots\n",
        "map_decode_8 = {\n",
        "    0: 'running',\n",
        "    1: 'walking',\n",
        "    2: 'jumping',\n",
        "    3: 'standing',\n",
        "    4: 'sitting',\n",
        "    5: 'lying',\n",
        "    6: 'falling',\n",
        "    7: 'transition'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kB4FskfwEOlL",
        "colab_type": "text"
      },
      "source": [
        "The dataset provides the list of labels (\"activities\") for each segment of tracked data, along with index bounds (start and stop) for each item of the list.\n",
        "\n",
        "Outside these ranges, data is considered to be marked as transitions between classes.\n",
        "\n",
        "This structure is flatten to a single list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5Z9H1Tv-W2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten_labels(labels, bounds):\n",
        "    \"\"\"Builds a single labels array from labels and bounds.\"\"\"\n",
        "    start = bounds[0::2]-1 # even positions\n",
        "    stop  = bounds[1::2]   # -1: numbering starts from 1\n",
        "    # start is included, stop is excluded\n",
        "    \n",
        "    res = np.ones(bounds[-1], dtype=np.uint8) * map_encode['TRANSIT']\n",
        "    for i, lab in enumerate(labels):\n",
        "        if i+1 < len(stop):\n",
        "            if stop[i] > start[i+1]+1:\n",
        "                # advance next start, mislabeling error\n",
        "                print('Time error: {} > {}'.format(stop[i],start[i+1]), end=' ')\n",
        "                start[i+1] = stop[i]\n",
        "        res[start[i] : stop[i]] = lab\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVcomuAZEi2r",
        "colab_type": "text"
      },
      "source": [
        "Datasets contain IMU measurements referred to the sensor frame, but also provides the attitude/cosine matrix to express the measurements w.r.t. the body frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsd0NVgF-xHd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_body_frame(imu_data, attitude_matrix):\n",
        "    \"\"\"Converts sensor frames in a data item to body frames through the attitude matrix.\"\"\"\n",
        "    C = attitude_matrix[1:].reshape(3,3).T\n",
        "\n",
        "    result = imu_data.copy()\n",
        "    result[1:4]  = np.dot(C, imu_data[1:4].T)  # acc\n",
        "    result[4:7]  = np.dot(C, imu_data[4:7].T)  # gyro\n",
        "    result[7:10] = np.dot(C, imu_data[7:10].T) # mag\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Ladk5mE9EP",
        "colab_type": "text"
      },
      "source": [
        "For each test in a dataset, extract the relevant data and then flat the labels to a single long list.\n",
        "\n",
        "The rest of the processing is postponed to operate on the full dataset instead of working on single tests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke3Npi6a_u0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_single_test(dataset, key):\n",
        "    imu_data, attitude_matrices, activities, activities_bounds = dataset[key][0]\n",
        "\n",
        "    # throwing away useless nested arrays\n",
        "    activities = np.array([ act[0] for act in activities[0] ])\n",
        "    activities_bounds = activities_bounds[0]\n",
        "    \n",
        "    # integrity checks on time and length\n",
        "    assert([ imu_data[i][0] == attitude_matrices[i][0] for i in range(len(imu_data)) ])\n",
        "    assert(len(activities_bounds) == 2*len(activities))\n",
        "\n",
        "    # change labels to int numbers\n",
        "    activities = np.array([ map_encode[a] for a in activities ])\n",
        "\n",
        "    # get a single array of labels instead of labels + bounds\n",
        "    activities_flat = flatten_labels(activities, activities_bounds)\n",
        "    assert(len(imu_data) == len(activities_flat))\n",
        "\n",
        "    info_dict = {\n",
        "        'name': key,\n",
        "        'act_list': [ map_decode_8[map_encode_8[i]] for i in activities ],\n",
        "        'act': [ (int(a),int(i),int(f)) for a,i,f in zip(activities, activities_bounds[0::2], activities_bounds[1::2]) ] }\n",
        "    \n",
        "    return imu_data, attitude_matrices, activities_flat, info_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLbeEpQXFdtH",
        "colab_type": "text"
      },
      "source": [
        "Numpy arrays are used to store all the collected data from every test in each dataset.\n",
        "\n",
        "For some relevant tests (those with a good mix of activities) plots of the (normalized) magnitude of IMU vectors are saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKlBfX4BBvHq",
        "colab_type": "code",
        "outputId": "93eba887-32a8-42bf-c0da-da5386b2086f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1563284107728,
          "user_tz": -120,
          "elapsed": 38,
          "user": {
            "displayName": "Filippo Rigotto",
            "photoUrl": "https://lh5.googleusercontent.com/-QEsn5Mr15CI/AAAAAAAAAAI/AAAAAAAAAFI/FgAME8VxJl8/s64/photo.jpg",
            "userId": "00487598020659430024"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "imu_sensor = np.empty((0,10))\n",
        "attitude_mat = np.empty((0,10))\n",
        "activities = np.empty((0,1), dtype=np.uint8)\n",
        "info_list = [] # just for keeping info about single tests\n",
        "\n",
        "tests_to_plot = [\n",
        "    'ARS_Cristina_Test_JmpFall_Sensor_Right',\n",
        "    'ARS_Hanno_Test_JmpFall_Sensor_Right',\n",
        "    'ARS_Maria_Test_JmpFall_Sensor_Left',\n",
        "    'ARS_Paula_Benchmark_Sensor_Left',\n",
        "    'ARS_Sinja_Benchmark_Sensor_Left',\n",
        "    'ARS_Emil_Benchmark_Sensor_Right'\n",
        "]\n",
        "tests_to_plot.clear() # no more plots to save\n",
        "\n",
        "# loop datasets\n",
        "for ds in datasets:\n",
        "    dataset = scipy.io.loadmat(ds)\n",
        "    keys = [ k for k in dataset if '__' not in k ]\n",
        "    # loop keys=tests\n",
        "    for test in keys:\n",
        "        print('Loading {}:'.format(test).ljust(52,' '), end='')\n",
        "        imu, mat, act, info = process_single_test(dataset, test)\n",
        "        imu_sensor = np.append(imu_sensor, imu, axis=0)\n",
        "        attitude_mat = np.append(attitude_mat, mat, axis=0)\n",
        "        activities = np.append(activities, act)\n",
        "        \n",
        "        info['start'] = int(imu_sensor.shape[0] - imu.shape[0])\n",
        "        info['end'] = int(imu_sensor.shape[0] - 1)\n",
        "        info_list.append(info)\n",
        "        print('{} elements'.format(imu.shape[0]).rjust(15,' '), end='')\n",
        "        \n",
        "        if test in tests_to_plot:\n",
        "            print('\\tSaving magnitude plots...', end='')\n",
        "            x = range(imu.shape[0])\n",
        "            acc = np.linalg.norm(imu[:,1:4],  axis=1) # vector magnitude\n",
        "            gyr = np.linalg.norm(imu[:,4:7],  axis=1)\n",
        "            mag = np.linalg.norm(imu[:,7:10], axis=1)\n",
        "            acc /= acc.max() # normalization\n",
        "            gyr /= gyr.max()\n",
        "            mag /= mag.max()\n",
        "            \n",
        "            act2 = [ map_encode_8[a] for a in act ]\n",
        "            cmap8 = mpl.cm.get_cmap('tab10', 8)\n",
        "            fig, (pa,pg,pm) = plt.subplots(3, 1, sharex=True)\n",
        "            #fig.suptitle(test, y=0.95, fontsize=16) # no title: will go in figure's caption\n",
        "            pa.scatter(x, acc, s=1, c=act2, cmap=cmap8)\n",
        "            pg.scatter(x, gyr, s=1, c=act2, cmap=cmap8)\n",
        "            pm.scatter(x, mag, s=1, c=act2, cmap=cmap8)\n",
        "            pa.set_ylabel('Accelerometer')\n",
        "            pg.set_ylabel('Gyroscope')\n",
        "            pm.set_ylabel('Magnetometer')\n",
        "            pm.set_xlabel('Time')\n",
        "            \n",
        "            #cb = plt.colorbar(sc) # sc = first plt.scatter\n",
        "            #cb.set_ticks(np.arange(8) + 0.5)\n",
        "            #cmap_labels = list(map_decode_8.values())\n",
        "            #cb.set_ticklabels(cmap_labels)#.append(' '))\n",
        "            \n",
        "            #fig.tight_layout(rect=[0, 0, 1, 0.93])\n",
        "            fig.tight_layout()\n",
        "            fname = os.path.join('.', 'report-misc', test)\n",
        "            fig.savefig(fname+'.png')\n",
        "            fig.savefig(fname+'.pdf', format='pdf')\n",
        "            plt.close()\n",
        "        print()\n",
        "        \n",
        "assert(imu_sensor.shape==attitude_mat.shape)\n",
        "num_data = imu_sensor.shape[0]\n",
        "\n",
        "# save info file for reference\n",
        "with open('report-misc/test-info.json','w') as info_file:\n",
        "    json.dump(info_list, info_file, indent=2)\n",
        "\n",
        "clear_output()\n",
        "print('Read {} records'.format(num_data))\n",
        "print('IMU data shape:   {}'.format(imu_sensor.shape))\n",
        "print('Attitudes shape:  {}'.format(attitude_mat.shape))\n",
        "print('Activities shape: {}'.format(activities.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read 2188965 records\n",
            "IMU data shape:   (2188965, 10)\n",
            "Attitudes shape:  (2188965, 10)\n",
            "Activities shape: (2188965,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0K15js_bM1K",
        "colab_type": "text"
      },
      "source": [
        "Save label's color palette, useful in report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxSyiunRUY7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = mpl.cm.get_cmap('tab10',8)\n",
        "\n",
        "colors = np.array(cm.colors)\n",
        "colors255 = np.round(colors*255)[:,:-1].astype(np.uint8) # no alpha channel\n",
        "\n",
        "np.savetxt(\"report-misc/colors.csv\",    colors,    delimiter=',', fmt='%.5f')\n",
        "np.savetxt(\"report-misc/colors255.csv\", colors255, delimiter=',', fmt='%d')\n",
        "\n",
        "indices = np.arange(8).reshape(1,8)\n",
        "arr = colors255[indices]\n",
        "arr = np.repeat(arr, 500, axis=0)\n",
        "arr = np.repeat(arr, 300, axis=1)\n",
        "\n",
        "skimage.io.imsave('report-misc/colors.jpg', arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXeJ_ymQLYvn",
        "colab_type": "text"
      },
      "source": [
        "Performing some checks:\n",
        "\n",
        "- Displaying minutes for each activity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coFWmHUDLdJJ",
        "colab_type": "code",
        "outputId": "6e521525-66ec-4f09-b966-d319f809fc19",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1563284107749,
          "user_tz": -120,
          "elapsed": 23718,
          "user": {
            "displayName": "Filippo Rigotto",
            "photoUrl": "https://lh5.googleusercontent.com/-QEsn5Mr15CI/AAAAAAAAAAI/AAAAAAAAAFI/FgAME8VxJl8/s64/photo.jpg",
            "userId": "00487598020659430024"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        }
      },
      "source": [
        "act,cnt = np.unique(activities, return_counts=True)\n",
        "cnt = cnt / 100 / 60 # 100 Hz, 60 seconds\n",
        "act = np.array([labels[a].lower() for a in act])\n",
        "\n",
        "act = np.append(act,'total')\n",
        "cnt = np.append(cnt, sum(cnt))\n",
        "\n",
        "df = pd.DataFrame(np.array([act,np.round(cnt)]).T, columns=['Activity','Time (min)'])\n",
        "df.index = [''] * len(df) # blank index\n",
        "display(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Activity</th>\n",
              "      <th>Time (min)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>running</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>walking</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>jumping</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>stnding</td>\n",
              "      <td>121.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>sitting</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>xlyingx</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>falling</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>walkups</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>walkdws</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>jumpvrt</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>jumpfwd</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>jumpbck</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>transup</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>transdw</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>trnsacc</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>trnsdcc</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>transit</td>\n",
              "      <td>53.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>total</td>\n",
              "      <td>365.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              " Activity Time (min)\n",
              "  running       15.0\n",
              "  walking       62.0\n",
              "  jumping        5.0\n",
              "  stnding      121.0\n",
              "  sitting       59.0\n",
              "  xlyingx       28.0\n",
              "  falling        2.0\n",
              "  walkups        6.0\n",
              "  walkdws        5.0\n",
              "  jumpvrt        1.0\n",
              "  jumpfwd        1.0\n",
              "  jumpbck        1.0\n",
              "  transup        4.0\n",
              "  transdw        2.0\n",
              "  trnsacc        1.0\n",
              "  trnsdcc        0.0\n",
              "  transit       53.0\n",
              "    total      365.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_-gvcNBHKkd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## More processing\n",
        "\n",
        "Starting from the whole dataset:\n",
        "- Reduce the number of tracked activities to 8\n",
        "- Remove of items labelled as transitions\n",
        "- Conversion of measurements to the body frame\n",
        "- Remove time columns (in both measurements and attitude matrixes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27hU5N27eRXt",
        "colab_type": "code",
        "outputId": "3a724a33-e774-484a-940e-92373d7fb21f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1563284111938,
          "user_tz": -120,
          "elapsed": 27873,
          "user": {
            "displayName": "Filippo Rigotto",
            "photoUrl": "https://lh5.googleusercontent.com/-QEsn5Mr15CI/AAAAAAAAAAI/AAAAAAAAAFI/FgAME8VxJl8/s64/photo.jpg",
            "userId": "00487598020659430024"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# remap activities\n",
        "print('Old labels: {}'.format(np.unique(activities)))\n",
        "activities = np.array([ map_encode_8[act] for act in activities])\n",
        "print('New labels: {}'.format(np.unique(activities)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Old labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
            "New labels: [0 1 2 3 4 5 6 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqcmtN6erf1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save times as latex table for report\n",
        "act,cnt = np.unique(activities, return_counts=True)\n",
        "cnt = cnt / 100 / 60\n",
        "act = np.array([map_decode_8[a] for a in act])\n",
        "\n",
        "act = np.append(act,'total')\n",
        "cnt = np.append(cnt, sum(cnt))\n",
        "\n",
        "df = pd.DataFrame(np.array([act,np.round(cnt)]).T, columns=['Activity','Time (min)'])\n",
        "df.index = [''] * len(df)\n",
        "\n",
        "with open('report-misc/act-times1.tex','w') as tfile:\n",
        "    tfile.write(df.to_latex(index=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKtvqG1aHLzP",
        "colab_type": "code",
        "outputId": "2c081651-00dc-494f-f81c-27090913ea50",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1563284117018,
          "user_tz": -120,
          "elapsed": 32898,
          "user": {
            "displayName": "Filippo Rigotto",
            "photoUrl": "https://lh5.googleusercontent.com/-QEsn5Mr15CI/AAAAAAAAAAI/AAAAAAAAAFI/FgAME8VxJl8/s64/photo.jpg",
            "userId": "00487598020659430024"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# remove transitions\n",
        "transit_label = map_encode_8[map_encode['TRANSIT']]\n",
        "transit_number = sum(activities == transit_label)\n",
        "print('Transit label is {}, found {} elements'.format(transit_label, transit_number))\n",
        "\n",
        "num_data = len(imu_sensor)\n",
        "print('Old num data: {}'.format(num_data))\n",
        "imu_sensor = imu_sensor[activities != transit_label]\n",
        "attitude_mat = attitude_mat[activities != transit_label]\n",
        "activities = activities[activities != transit_label]\n",
        "\n",
        "assert(imu_sensor.shape[0] == num_data-transit_number)\n",
        "assert(attitude_mat.shape[0] == num_data-transit_number)\n",
        "assert(activities.shape[0] == num_data-transit_number)\n",
        "\n",
        "num_data = len(imu_sensor)\n",
        "print('New num data: {}'.format(num_data))\n",
        "\n",
        "num_labels = len(np.unique(activities))\n",
        "print('New num labels: {}'.format(num_labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transit label is 7, found 361319 elements\n",
            "Old num data: 2188965\n",
            "New num data: 1827646\n",
            "New num labels: 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9ngv9Uwd8jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert from sensor frame to body frame\n",
        "imu_body = imu_sensor.copy()\n",
        "for i, imu in enumerate(imu_sensor):\n",
        "    imu_body[i] = convert_body_frame(imu, attitude_mat[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gkhe3BMd-Se",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove time column from data\n",
        "imu_sensor = imu_sensor[:,1:]\n",
        "imu_body = imu_body[:,1:]\n",
        "attitude_mat = attitude_mat[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGxV0TGtLgYm",
        "colab_type": "text"
      },
      "source": [
        "Performing some checks:\n",
        "\n",
        "- Displaying minutes for each activity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlBD0dxyLhqH",
        "colab_type": "code",
        "outputId": "f16aaec6-e541-4299-fb45-db9e3dda5d14",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1563284130093,
          "user_tz": -120,
          "elapsed": 45911,
          "user": {
            "displayName": "Filippo Rigotto",
            "photoUrl": "https://lh5.googleusercontent.com/-QEsn5Mr15CI/AAAAAAAAAAI/AAAAAAAAAFI/FgAME8VxJl8/s64/photo.jpg",
            "userId": "00487598020659430024"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "act,cnt = np.unique(activities, return_counts=True)\n",
        "cnt = cnt / 100 / 60\n",
        "act = np.array([map_decode_8[a] for a in act])\n",
        "\n",
        "act = np.append(act,'total')\n",
        "cnt = np.append(cnt, sum(cnt))\n",
        "\n",
        "df = pd.DataFrame(np.array([act,np.round(cnt)]).T, columns=['Activity','Time (min)'])\n",
        "df.index = [''] * len(df)\n",
        "display(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Activity</th>\n",
              "      <th>Time (min)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>running</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>walking</td>\n",
              "      <td>72.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>jumping</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>standing</td>\n",
              "      <td>121.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>sitting</td>\n",
              "      <td>59.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>lying</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>falling</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <td>total</td>\n",
              "      <td>305.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Activity Time (min)\n",
              "   running       15.0\n",
              "   walking       72.0\n",
              "   jumping        8.0\n",
              "  standing      121.0\n",
              "   sitting       59.0\n",
              "     lying       28.0\n",
              "   falling        2.0\n",
              "     total      305.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlQj-FHruzD2",
        "colab_type": "text"
      },
      "source": [
        "Pre-compute and save a train/test split of the dataset.\n",
        "\n",
        "`random_state` is the seed of the PRNG, the percentage is set using `SPLIT_TEST_PERC` variable.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_rP0qgZuwCM",
        "colab_type": "code",
        "outputId": "2df93466-12c4-42b1-ef67-321e9760837a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1563284133157,
          "user_tz": -120,
          "elapsed": 48948,
          "user": {
            "displayName": "Filippo Rigotto",
            "photoUrl": "https://lh5.googleusercontent.com/-QEsn5Mr15CI/AAAAAAAAAAI/AAAAAAAAAFI/FgAME8VxJl8/s64/photo.jpg",
            "userId": "00487598020659430024"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "SPLIT_TEST_PERC = 0.3\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = \\\n",
        "    train_test_split(imu_sensor, activities, test_size=SPLIT_TEST_PERC, random_state=1, stratify=activities) \n",
        "\n",
        "print(\"X_train shape: \" + str(X_train.shape))\n",
        "print(\"Y_train shape: \" + str(len(Y_train)))\n",
        "print(\"X_test shape:  \" + str(X_test.shape))\n",
        "print(\"Y_test shape:  \" + str(len(Y_test)))\n",
        "\n",
        "Xb_train, Xb_test, Yb_train, Yb_test = \\\n",
        "    train_test_split(imu_body, activities, test_size=SPLIT_TEST_PERC, random_state=1, stratify=activities) \n",
        "\n",
        "print(\"Xb_train shape: \" + str(Xb_train.shape))\n",
        "print(\"Yb_train shape: \" + str(len(Yb_train)))\n",
        "print(\"Xb_test shape:  \" + str(Xb_test.shape))\n",
        "print(\"Yb_test shape:  \" + str(len(Yb_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (1279352, 9)\n",
            "Y_train shape: 1279352\n",
            "X_test shape:  (548294, 9)\n",
            "Y_test shape:  548294\n",
            "Xb_train shape: (1279352, 9)\n",
            "Yb_train shape: 1279352\n",
            "Xb_test shape:  (548294, 9)\n",
            "Yb_test shape:  548294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtESTYRbunOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with h5py.File('dataset/ARS-train-test-sensor.h5','w') as h5f:\n",
        "    h5f.create_dataset('X_train', data=X_train)\n",
        "    h5f.create_dataset('X_test',  data=X_test)\n",
        "    h5f.create_dataset('Y_train', data=Y_train)\n",
        "    h5f.create_dataset('Y_test',  data=Y_test)\n",
        "    \n",
        "with h5py.File('dataset/ARS-train-test-body.h5','w') as h5f:\n",
        "    h5f.create_dataset('X_train', data=Xb_train)\n",
        "    h5f.create_dataset('X_test',  data=Xb_test)\n",
        "    h5f.create_dataset('Y_train', data=Yb_train)\n",
        "    h5f.create_dataset('Y_test',  data=Yb_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BJbsBq-MlC_",
        "colab_type": "text"
      },
      "source": [
        "## Framing\n",
        "\n",
        "Group by activity and organize data in overlapping windows (overlapping ratio is regulated by `stride_len`). \n",
        "\n",
        "Save the resulting dataset and a corresponding split."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms44alUwMmYL",
        "colab_type": "code",
        "outputId": "a59b9b10-5d79-4870-d0a7-eb9667449261",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1563284134374,
          "user_tz": -120,
          "elapsed": 50120,
          "user": {
            "displayName": "Filippo Rigotto",
            "photoUrl": "https://lh5.googleusercontent.com/-QEsn5Mr15CI/AAAAAAAAAAI/AAAAAAAAAFI/FgAME8VxJl8/s64/photo.jpg",
            "userId": "00487598020659430024"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "window_len = 128\n",
        "stride_len = round(window_len / 2)\n",
        "\n",
        "def framing_padding(data):\n",
        "    x, y = [], []\n",
        "\n",
        "    for activity in np.unique(activities):\n",
        "        tmp = data[activities == activity]\n",
        "        if len(tmp) % stride_len != 0:\n",
        "            # append zeroes to fill the window, if necessary\n",
        "            windows_inside = math.ceil( (len(tmp) - window_len) / stride_len )\n",
        "            windows_space = windows_inside * stride_len\n",
        "            rest = windows_space - len(tmp) + window_len\n",
        "            #print('Act. {}, appending {} rows of zeros'.format(activity,rest))\n",
        "\n",
        "            tmp = np.append(tmp, np.zeros((rest,data.shape[1])), axis=0)\n",
        "            #tmp = np.append(tmp, [[0]*9]*int((math.floor((len(tmp)-window_len)/stride_len) + 1)*stride_len-len(tmp)+window_len), axis = 0)\n",
        "\n",
        "        # exlude unnecessary padded windows\n",
        "        for i in range(0, len(tmp)-window_len, stride_len):\n",
        "            x.extend([tmp[i:i+window_len]])\n",
        "            y.extend([activity])\n",
        "\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    assert(x.shape[0] == len(y))\n",
        "    return x,y\n",
        "\n",
        "imu_sensor_framed, activities_sensor_framed = framing_padding(imu_sensor)\n",
        "imu_body_framed, activities_body_framed = framing_padding(imu_body)\n",
        "\n",
        "assert(np.array_equal(activities_sensor_framed, activities_body_framed))\n",
        "\n",
        "print(\"IMU_sensor shape: \" + str(imu_sensor_framed.shape))\n",
        "print(\"IMU body shape:   \" + str(imu_body_framed.shape))\n",
        "print(\"Activities shape: \" + str(len(activities_sensor_framed)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IMU_sensor shape: (28545, 128, 9)\n",
            "IMU body shape:   (28545, 128, 9)\n",
            "Activities shape: 28545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXz4oqm2UpNd",
        "colab_type": "code",
        "outputId": "4308c0cd-26db-4815-dc32-f2675f13eebb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1563284135430,
          "user_tz": -120,
          "elapsed": 51146,
          "user": {
            "displayName": "Filippo Rigotto",
            "photoUrl": "https://lh5.googleusercontent.com/-QEsn5Mr15CI/AAAAAAAAAAI/AAAAAAAAAFI/FgAME8VxJl8/s64/photo.jpg",
            "userId": "00487598020659430024"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = \\\n",
        "    train_test_split(imu_sensor_framed, activities_sensor_framed, test_size=SPLIT_TEST_PERC, random_state=1, stratify=activities_sensor_framed) \n",
        "\n",
        "print(\"X_train shape: \" + str(X_train.shape))\n",
        "print(\"Y_train shape: \" + str(len(Y_train)))\n",
        "print(\"X_test shape:  \" + str(X_test.shape))\n",
        "print(\"Y_test shape:  \" + str(len(Y_test)))\n",
        "\n",
        "Xb_train, Xb_test, Yb_train, Yb_test = \\\n",
        "    train_test_split(imu_body_framed, activities_body_framed, test_size=SPLIT_TEST_PERC, random_state=1, stratify=activities_body_framed) \n",
        "\n",
        "print(\"Xb_train shape: \" + str(Xb_train.shape))\n",
        "print(\"Yb_train shape: \" + str(len(Yb_train)))\n",
        "print(\"Xb_test shape:  \" + str(Xb_test.shape))\n",
        "print(\"Yb_test shape:  \" + str(len(Yb_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (19981, 128, 9)\n",
            "Y_train shape: 19981\n",
            "X_test shape:  (8564, 128, 9)\n",
            "Y_test shape:  8564\n",
            "Xb_train shape: (19981, 128, 9)\n",
            "Yb_train shape: 19981\n",
            "Xb_test shape:  (8564, 128, 9)\n",
            "Yb_test shape:  8564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p87LKo2sNo_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with h5py.File('dataset/ARS-train-test-sensor-framed.h5','w') as h5f:\n",
        "    h5f.create_dataset('X_train', data=X_train)\n",
        "    h5f.create_dataset('X_test',  data=X_test)\n",
        "    h5f.create_dataset('Y_train', data=Y_train)\n",
        "    h5f.create_dataset('Y_test',  data=Y_test)\n",
        "\n",
        "with h5py.File('dataset/ARS-train-test-body-framed.h5','w') as h5f:\n",
        "    h5f.create_dataset('X_train', data=Xb_train)\n",
        "    h5f.create_dataset('X_test',  data=Xb_test)\n",
        "    h5f.create_dataset('Y_train', data=Yb_train)\n",
        "    h5f.create_dataset('Y_test',  data=Yb_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYjKh3cI8vXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "act,cnt = np.unique(activities_sensor_framed, return_counts=True)\n",
        "cnt = cnt * 128 / 100 / 60\n",
        "act = np.array([map_decode_8[a] for a in act])\n",
        "\n",
        "act = np.append(act,'total')\n",
        "cnt = np.append(cnt, sum(cnt))\n",
        "\n",
        "df = pd.DataFrame(np.array([act,np.round(cnt)]).T, columns=['Activity','Time (min)'])\n",
        "df.index = [''] * len(df)\n",
        "\n",
        "with open('report-misc/act-times2.tex','w') as tfile:\n",
        "    tfile.write(df.to_latex(index=False))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnRFt7ML-WW-",
        "colab_type": "text"
      },
      "source": [
        "## Augmentation\n",
        "\n",
        "Data augmentation is performed using the Adaptive Syntetic (ADASYN) sampling algorithm, since this dataset is not balanced.\n",
        "\n",
        "More information on the algorithm can be found in the paper [(link)](https://ieeexplore.ieee.org/document/4633969): \n",
        " \n",
        "    Haibo He, Yang Bai, Edwardo A. Garcia, and Shutao Li. \u201cADASYN: Adaptive synthetic sampling approach for imbalanced learning,\u201d In IEEE International Joint Conference on Neural Networks, pp. 1322-1328, 2008.\n",
        "\n",
        "We use the implementation included in the [imbalanced-learn](https://imbalanced-learn.readthedocs.io) Python package.\n",
        "\n",
        "Use the switch below to choose whether to augment only training set or the whole dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKAvyzWQ5PE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augment_only_train = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ5CznScAo5V",
        "colab_type": "code",
        "outputId": "26347ddc-1566-4530-a6e2-9255b7cd618b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1563284319877,
          "user_tz": -120,
          "elapsed": 235512,
          "user": {
            "displayName": "Filippo Rigotto",
            "photoUrl": "https://lh5.googleusercontent.com/-QEsn5Mr15CI/AAAAAAAAAAI/AAAAAAAAAFI/FgAME8VxJl8/s64/photo.jpg",
            "userId": "00487598020659430024"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "if augment_only_train:\n",
        "    # start from X_train and Xb_train\n",
        "    # ADASYN accepts 2d arrays, so we squeeze last two dimensions\n",
        "    imu_sensor_2d = X_train.reshape((X_train.shape[0], X_train.shape[2]*X_train.shape[1]))\n",
        "    imu_body_2d = Xb_train.reshape((Xb_train.shape[0], Xb_train.shape[2]*Xb_train.shape[1]))\n",
        "    print(f\"{X_train.shape} > {imu_sensor_2d.shape}\")\n",
        "    print(f\"{Xb_train.shape} > {imu_body_2d.shape}\")\n",
        "\n",
        "    # to have comparable results to manual augmentation written below, try to keep proportions between classes\n",
        "    \"\"\"\n",
        "    Class 0: 986 entries, 1787 values to add, totalling 2773.\n",
        "    Class 1: 4733 entries, OK\n",
        "    Class 2: 496 entries, 2277 values to add, totalling 2773.\n",
        "    Class 3: 7923 entries, OK\n",
        "    Class 4: 3863 entries, OK\n",
        "    Class 5: 1851 entries, 922 values to add, totalling 2773.\n",
        "    Class 6: 129 entries, 2644 values to add, totalling 2773.\n",
        "    \"\"\"\n",
        "    \n",
        "    sample_num_dict = {\n",
        "        0: 2773,\n",
        "        1: 4733,  # not augmented\n",
        "        2: 2773,\n",
        "        3: 7923,  # not augmented\n",
        "        4: 3863,  # not augmented\n",
        "        5: 2773,\n",
        "        6: 2773\n",
        "    }\n",
        "\n",
        "    ada = ADASYN(random_state=8, n_jobs=2, sampling_strategy=sample_num_dict)\n",
        "    imu_sensor_framed_aug, activities_sensor_framed_aug = ada.fit_resample(imu_sensor_2d, Y_train)\n",
        "    print(f'Resampled composition: {Counter(activities_sensor_framed_aug)}')\n",
        "\n",
        "    ada = ADASYN(random_state=8, n_jobs=2, sampling_strategy=sample_num_dict)\n",
        "    imu_body_framed_aug, activities_body_framed_aug = ada.fit_resample(imu_body_2d, Yb_train)\n",
        "    print(f'Resampled composition: {Counter(activities_body_framed_aug)}')\n",
        "\n",
        "    # back to three dimensions arrays\n",
        "    imu_sensor_framed_aug = imu_sensor_framed_aug.reshape((-1,X_train.shape[1],X_train.shape[2]))\n",
        "    imu_body_framed_aug = imu_body_framed_aug.reshape((-1,Xb_train.shape[1],Xb_train.shape[2]))\n",
        "    \n",
        "else:\n",
        "    #start from imu_sensor/body_framed\n",
        "    imu_sensor_2d = imu_sensor_framed.reshape((imu_sensor_framed.shape[0], imu_sensor_framed.shape[2]*imu_sensor_framed.shape[1]))\n",
        "    imu_body_2d = imu_body_framed.reshape((imu_body_framed.shape[0], imu_body_framed.shape[2]*imu_body_framed.shape[1]))\n",
        "    print(f\"{imu_sensor_framed.shape} > {imu_sensor_2d.shape}\")\n",
        "    print(f\"{imu_body_framed.shape} > {imu_body_2d.shape}\")\n",
        "\n",
        "    \"\"\"\n",
        "    Class 0: 1409 entries, 2552 values to add, totalling 3961.\n",
        "    Class 1: 6762 entries, OK\n",
        "    Class 2: 709 entries, 3252 values to add, totalling 3961.\n",
        "    Class 3: 11319 entries, OK\n",
        "    Class 4: 5518 entries, OK\n",
        "    Class 5: 2644 entries, 1317 values to add, totalling 3961.\n",
        "    Class 6: 184 entries, 3777 values to add, totalling 3961.\n",
        "    \"\"\"\n",
        "\n",
        "    sample_num_dict = {\n",
        "        0: 3961,\n",
        "        1: 6762,  # not augmented\n",
        "        2: 3961,\n",
        "        3: 11319, # not augmented\n",
        "        4: 5518,  # not augmented\n",
        "        5: 3961,\n",
        "        6: 3961\n",
        "    }\n",
        "\n",
        "    ada = ADASYN(random_state=8, n_jobs=2, sampling_strategy=sample_num_dict)\n",
        "    imu_sensor_framed_aug, activities_sensor_framed_aug = ada.fit_resample(imu_sensor_2d, activities_sensor_framed)\n",
        "    print(f'Resampled composition: {Counter(activities_sensor_framed_aug)}')\n",
        "\n",
        "    ada = ADASYN(random_state=8, n_jobs=2, sampling_strategy=sample_num_dict)\n",
        "    imu_body_framed_aug, activities_body_framed_aug = ada.fit_resample(imu_body_2d, activities_body_framed)\n",
        "    print(f'Resampled composition: {Counter(activities_body_framed_aug)}')\n",
        "\n",
        "    imu_sensor_framed_aug = imu_sensor_framed_aug.reshape((-1,imu_sensor_framed.shape[1],imu_sensor_framed.shape[2]))\n",
        "    imu_body_framed_aug = imu_body_framed_aug.reshape((-1,imu_body_framed.shape[1],imu_body_framed.shape[2]))\n",
        "\n",
        "print(imu_sensor_framed_aug.shape)\n",
        "print(imu_body_framed_aug.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19981, 128, 9) > (19981, 1152)\n",
            "(19981, 128, 9) > (19981, 1152)\n",
            "Resampled composition: Counter({3: 7923, 1: 4733, 4: 3863, 2: 2790, 6: 2785, 5: 2775, 0: 2768})\n",
            "Resampled composition: Counter({3: 7923, 1: 4733, 4: 3863, 5: 2832, 0: 2813, 6: 2806, 2: 2804})\n",
            "(27637, 128, 9)\n",
            "(27774, 128, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFXa3ChGBzw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if augment_only_train:\n",
        "    X_trainA = imu_sensor_framed_aug.copy()\n",
        "    Y_trainA = activities_sensor_framed_aug.copy()\n",
        "    X_testA = X_test.copy()\n",
        "    Y_testA = Y_test.copy()\n",
        "\n",
        "    Xb_trainA = imu_body_framed_aug.copy()\n",
        "    Yb_trainA = activities_body_framed_aug.copy()\n",
        "    Xb_testA = Xb_test.copy()\n",
        "    Yb_testA = Yb_test.copy()\n",
        "else:\n",
        "    X_trainA, X_testA, Y_trainA, Y_testA = \\\n",
        "        train_test_split(imu_sensor_framed_aug, activities_sensor_framed_aug, test_size=SPLIT_TEST_PERC, random_state=1, stratify=activities_sensor_framed_aug)\n",
        "    Xb_trainA, Xb_testA, Yb_trainA, Yb_testA = \\\n",
        "        train_test_split(imu_body_framed_aug,   activities_body_framed_aug,   test_size=SPLIT_TEST_PERC, random_state=1, stratify=activities_body_framed_aug)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9RN0OE2B1fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if augment_only_train:\n",
        "    name = 'dataset/ARS-train-test-{}-framed-aug-onlytrain.h5'    \n",
        "else:\n",
        "    name = 'dataset/ARS-train-test-{}-framed-aug.h5'\n",
        "\n",
        "with h5py.File(name.format('sensor'),'w') as h5f:\n",
        "    h5f.create_dataset('X_train', data=X_trainA)\n",
        "    h5f.create_dataset('X_test',  data=X_testA)\n",
        "    h5f.create_dataset('Y_train', data=Y_trainA)\n",
        "    h5f.create_dataset('Y_test',  data=Y_testA)\n",
        "\n",
        "with h5py.File(name.format('body'),'w') as h5f:\n",
        "    h5f.create_dataset('X_train', data=Xb_trainA)\n",
        "    h5f.create_dataset('X_test',  data=Xb_testA)\n",
        "    h5f.create_dataset('Y_train', data=Yb_trainA)\n",
        "    h5f.create_dataset('Y_test',  data=Yb_testA)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXghZDlhXUET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "act,cnt = np.unique(activities_sensor_framed_aug, return_counts=True)\n",
        "cnt = cnt * 128 / 100 / 60\n",
        "act = np.array([map_decode_8[a] for a in act])\n",
        "\n",
        "act = np.append(act,'total')\n",
        "cnt = np.append(cnt, sum(cnt))\n",
        "\n",
        "df = pd.DataFrame(np.array([act,np.round(cnt)]).T, columns=['Activity','Time (min)'])\n",
        "df.index = [''] * len(df)\n",
        "\n",
        "with open('report-misc/act-times3a.tex','w') as tfile:\n",
        "    tfile.write(df.to_latex(index=False))\n",
        "    \n",
        "print()\n",
        "act,cnt = np.unique(Y_testA, return_counts=True)\n",
        "cnt = cnt * 128 / 100 / 60\n",
        "act = np.array([map_decode_8[a] for a in act])\n",
        "\n",
        "act = np.append(act,'total')\n",
        "cnt = np.append(cnt, sum(cnt))\n",
        "\n",
        "df2 = pd.DataFrame(np.array([act,np.round(cnt)]).T, columns=['Activity','Time (min)'])\n",
        "df2.index = [''] * len(df)\n",
        "\n",
        "with open('report-misc/act-times3b.tex','w') as tfile:\n",
        "    tfile.write(df.to_latex(index=False))\n",
        "\n",
        "# manual sum needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfxLG8Rr7f83",
        "colab_type": "text"
      },
      "source": [
        "## Manual Augmentation\n",
        "\n",
        "Instead of relying on an algorithm to augment data, this can be performed manually:\n",
        "\n",
        "- By applying a rotation of a random angle against a random axis (_not_ applied to classes _standing_ and _lying_,  due to worse performance), \n",
        "- By permutation of data in a window (_not_ applied to classes _jumping_ and _falling_ due to mislabeling).\n",
        "\n",
        "One or both operations may be carried out.\n",
        "\n",
        "To enable and configure the feature set the global switches below accordingly (or skip executing all next cells)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwzzSIqi1hy1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "manual_augment = True\n",
        "rotation  = True\n",
        "permutation = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbNIguAc7luF",
        "colab_type": "code",
        "outputId": "25d373ef-9f45-4d24-a4ba-b79df55c8932",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1563284400867,
          "user_tz": -120,
          "elapsed": 316414,
          "user": {
            "displayName": "Filippo Rigotto",
            "photoUrl": "https://lh5.googleusercontent.com/-QEsn5Mr15CI/AAAAAAAAAAI/AAAAAAAAAFI/FgAME8VxJl8/s64/photo.jpg",
            "userId": "00487598020659430024"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "def rotate_random(data):\n",
        "    # axis and angle of the rotation\n",
        "    axis = np.random.uniform(low=-1, high=1, size = 3)\n",
        "    angle = np.random.uniform(low=-np.pi, high=np.pi)\n",
        "        \n",
        "    res = data.copy()\n",
        "    for i in range(0,len(data),3):\n",
        "        res[i:i+3] = np.matmul(data[i:i+3], axangle2mat(axis,angle))\n",
        "    return res\n",
        "\n",
        "def rotate(values):\n",
        "    for i in range(values.shape[0]):\n",
        "        for j in range(values.shape[1]):\n",
        "            values[i,j] = rotate_random(values[i,j])\n",
        "    return values\n",
        "\n",
        "def chunks(l, n):\n",
        "    for i in range(0, len(l), n):\n",
        "        yield l[i:i+n]\n",
        "        \n",
        "def permute(values):\n",
        "    values = list(chunks(values,8))  #8*16=128\n",
        "    random.shuffle(values)\n",
        "    values = [i for crop_seq in values for i in crop_seq]\n",
        "    return np.array(values)\n",
        "   \n",
        "def augmenting(x, y, rotation=True, permutation=True):\n",
        "    np.random.seed(8) # to have the same choices for both sensor and body-related datasets\n",
        "    augm_factor = 0.35\n",
        "\n",
        "    count = []\n",
        "    for activity in np.unique(y):\n",
        "        count.append(len(x[y == activity]))\n",
        "    percentage_before = count/np.sum(count,axis=0)\n",
        "    most_repr = int(max(count)*augm_factor)\n",
        "\n",
        "    x_add = []\n",
        "    y_add = []\n",
        "    for activity in range(len(count)):\n",
        "        augment_number = most_repr - count[activity]\n",
        "        if augment_number > 0:\n",
        "            print(f\"Class {activity}: {count[activity]} entries, {augment_number} values to add, totalling {count[activity]+augment_number}.\")\n",
        "            values = x[np.array(y) == activity][np.random.choice(range(count[activity]),size=augment_number)]\n",
        "            if rotation and activity not in [4,5]: # exclude sitting, lying from random rotations\n",
        "                values = rotate(values)\n",
        "            if permutation and activity not in [2,6]: # exclude jumping, falling from permutations\n",
        "                values = permute(values)\n",
        "            x_add.extend(values)\n",
        "            y_add.extend([activity]*values.shape[0])\n",
        "        else:\n",
        "            print(f\"Class {activity}: {count[activity]} entries, OK\")\n",
        "    return np.array(x_add), np.array(y_add)\n",
        "\n",
        "if manual_augment:\n",
        "    if augment_only_train:\n",
        "        # get data to add\n",
        "        imu_sensor_toadd, activities_sensor_toadd = augmenting(X_train, Y_train, rotation, permutation)\n",
        "        print()\n",
        "        imu_body_toadd, activities_body_toadd = augmenting(Xb_train, Yb_train, rotation, permutation)\n",
        "\n",
        "        # add to existing data\n",
        "        imu_sensor_framed_aug = np.concatenate((X_train, imu_sensor_toadd), axis=0)\n",
        "        imu_body_framed_aug   = np.concatenate((Xb_train,   imu_body_toadd),   axis=0)\n",
        "        activities_sensor_framed_aug = np.concatenate((Y_train, activities_sensor_toadd), axis=0)\n",
        "        activities_body_framed_aug   = np.concatenate((Yb_train,   activities_body_toadd),   axis=0)\n",
        "\n",
        "        assert(len(imu_sensor_framed_aug) == len(X_train) + len(imu_sensor_toadd))\n",
        "        assert(len(imu_body_framed_aug)   == len(Xb_train)   + len(imu_body_toadd))\n",
        "        assert(len(activities_sensor_framed_aug) == len(Y_train) + len(activities_sensor_toadd))\n",
        "        assert(len(activities_body_framed_aug)   == len(Yb_train)   + len(activities_body_toadd))\n",
        "\n",
        "    else:\n",
        "        imu_sensor_toadd, activities_sensor_toadd = augmenting(imu_sensor_framed, activities_sensor_framed, rotation, permutation)\n",
        "        print()\n",
        "        imu_body_toadd, activities_body_toadd = augmenting(imu_body_framed, activities_body_framed, rotation, permutation)\n",
        "\n",
        "        # add to existing data\n",
        "        imu_sensor_framed_aug = np.concatenate((imu_sensor_framed, imu_sensor_toadd), axis=0)\n",
        "        imu_body_framed_aug   = np.concatenate((imu_body_framed,   imu_body_toadd),   axis=0)\n",
        "        activities_sensor_framed_aug = np.concatenate((activities_sensor_framed, activities_sensor_toadd), axis=0)\n",
        "        activities_body_framed_aug   = np.concatenate((activities_body_framed,   activities_body_toadd),   axis=0)\n",
        "\n",
        "        assert(len(imu_sensor_framed_aug) == len(imu_sensor_framed) + len(imu_sensor_toadd))\n",
        "        assert(len(imu_body_framed_aug)   == len(imu_body_framed)   + len(imu_body_toadd))\n",
        "        assert(len(activities_sensor_framed_aug) == len(activities_sensor_framed) + len(activities_sensor_toadd))\n",
        "        assert(len(activities_body_framed_aug)   == len(activities_body_framed)   + len(activities_body_toadd))\n",
        "    \n",
        "    print()\n",
        "    print(f'Resampled composition: {Counter(activities_sensor_framed_aug)}')\n",
        "    print(f'Resampled composition: {Counter(activities_body_framed_aug)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class 0: 986 entries, 1787 values to add, totalling 2773.\n",
            "Class 1: 4733 entries, OK\n",
            "Class 2: 496 entries, 2277 values to add, totalling 2773.\n",
            "Class 3: 7923 entries, OK\n",
            "Class 4: 3863 entries, OK\n",
            "Class 5: 1851 entries, 922 values to add, totalling 2773.\n",
            "Class 6: 129 entries, 2644 values to add, totalling 2773.\n",
            "\n",
            "Class 0: 986 entries, 1787 values to add, totalling 2773.\n",
            "Class 1: 4733 entries, OK\n",
            "Class 2: 496 entries, 2277 values to add, totalling 2773.\n",
            "Class 3: 7923 entries, OK\n",
            "Class 4: 3863 entries, OK\n",
            "Class 5: 1851 entries, 922 values to add, totalling 2773.\n",
            "Class 6: 129 entries, 2644 values to add, totalling 2773.\n",
            "\n",
            "Resampled composition: Counter({3: 7923, 1: 4733, 4: 3863, 0: 2773, 5: 2773, 2: 2773, 6: 2773})\n",
            "Resampled composition: Counter({3: 7923, 1: 4733, 4: 3863, 0: 2773, 5: 2773, 2: 2773, 6: 2773})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzSKlKFG7osu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if manual_augment:\n",
        "    if augment_only_train:\n",
        "        X_trainM = imu_sensor_framed_aug.copy()\n",
        "        Y_trainM = activities_sensor_framed_aug.copy()\n",
        "        X_testM = X_test.copy()\n",
        "        Y_testM = Y_test.copy()\n",
        "        \n",
        "        Xb_trainM = imu_body_framed_aug.copy()\n",
        "        Yb_trainM = activities_body_framed_aug.copy()\n",
        "        Xb_testM = Xb_test.copy()\n",
        "        Yb_testM = Yb_test.copy()\n",
        "    else:\n",
        "        X_trainM, X_testM, Y_trainM, Y_testM = \\\n",
        "            train_test_split(imu_sensor_framed_aug, activities_sensor_framed_aug, test_size=SPLIT_TEST_PERC, random_state=1, stratify=activities_sensor_framed_aug)\n",
        "        Xb_trainM, Xb_testM, Yb_trainM, Yb_testM = \\\n",
        "            train_test_split(imu_body_framed_aug,   activities_body_framed_aug,   test_size=SPLIT_TEST_PERC, random_state=1, stratify=activities_body_framed_aug)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLgAC_t-7rHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if manual_augment:\n",
        "    if augment_only_train:\n",
        "        name = 'dataset/ARS-train-test-{}-framed-aug-onlytrain'\n",
        "    else:\n",
        "        name = 'dataset/ARS-train-test-{}-framed-aug'\n",
        "    if rotation:    name += '-rot'\n",
        "    if permutation: name += '-per'\n",
        "    name += '.h5'\n",
        "    \n",
        "    with h5py.File(name.format('sensor'),'w') as h5f:\n",
        "        h5f.create_dataset('X_train', data=X_trainM)\n",
        "        h5f.create_dataset('X_test',  data=X_testM)\n",
        "        h5f.create_dataset('Y_train', data=Y_trainM)\n",
        "        h5f.create_dataset('Y_test',  data=Y_testM)\n",
        "\n",
        "    with h5py.File(name.format('body'),'w') as h5f:\n",
        "        h5f.create_dataset('X_train', data=Xb_trainM)\n",
        "        h5f.create_dataset('X_test',  data=Xb_testM)\n",
        "        h5f.create_dataset('Y_train', data=Yb_trainM)\n",
        "        h5f.create_dataset('Y_test',  data=Yb_testM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DIwfnLPXlZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "act,cnt = np.unique(activities_sensor_framed_aug, return_counts=True)\n",
        "cnt = cnt * 128 / 100 / 60\n",
        "act = np.array([map_decode_8[a] for a in act])\n",
        "\n",
        "act = np.append(act,'total')\n",
        "cnt = np.append(cnt, sum(cnt))\n",
        "\n",
        "df = pd.DataFrame(np.array([act,np.round(cnt)]).T, columns=['Activity','Time (min)'])\n",
        "df.index = [''] * len(df)\n",
        "\n",
        "with open('report-misc/act-times4a.tex','w') as tfile:\n",
        "    tfile.write(df.to_latex(index=False))\n",
        "    \n",
        "print()\n",
        "act,cnt = np.unique(Y_testM, return_counts=True)\n",
        "cnt = cnt * 128 / 100 / 60\n",
        "act = np.array([map_decode_8[a] for a in act])\n",
        "\n",
        "act = np.append(act,'total')\n",
        "cnt = np.append(cnt, sum(cnt))\n",
        "\n",
        "df2 = pd.DataFrame(np.array([act,np.round(cnt)]).T, columns=['Activity','Time (min)'])\n",
        "df2.index = [''] * len(df)\n",
        "\n",
        "with open('report-misc/act-times4b.tex','w') as tfile:\n",
        "    tfile.write(df.to_latex(index=False))\n",
        "\n",
        "# manual sum needed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQjCrfvvQkut",
        "colab_type": "text"
      },
      "source": [
        "## Normalization\n",
        "\n",
        "Data normalization is performed using training set's mean and std.\n",
        "\n",
        "Improves accuracy results: to be applied upon latest splits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kD60s-HQmUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# not augmented part\n",
        "for i in range(X_train.shape[-1]):\n",
        "    tmp_train = X_train[:,:,i].flatten()\n",
        "    tmp_test = X_test[:,:,i].flatten()\n",
        "    mean = np.mean(tmp_train)\n",
        "    std = np.std(tmp_train)\n",
        "    X_train[:,:,i] = np.reshape((tmp_train - mean)/std, (X_train.shape[0], X_train.shape[1]))\n",
        "    X_test[:,:,i] =  np.reshape((tmp_test - mean)/std, (X_test.shape[0], X_test.shape[1]))\n",
        "\n",
        "for i in range(Xb_train.shape[-1]):\n",
        "    tmp_train = Xb_train[:,:,i].flatten()\n",
        "    tmp_test = Xb_test[:,:,i].flatten()\n",
        "    mean = np.mean(tmp_train)\n",
        "    std = np.std(tmp_train)\n",
        "    Xb_train[:,:,i] = np.reshape((tmp_train - mean)/std, (Xb_train.shape[0], Xb_train.shape[1]))\n",
        "    Xb_test[:,:,i] =  np.reshape((tmp_test - mean)/std, (Xb_test.shape[0], Xb_test.shape[1]))\n",
        "\n",
        "\n",
        "# ADASYN aug part\n",
        "for i in range(X_trainA.shape[-1]):\n",
        "    tmp_train = X_trainA[:,:,i].flatten()\n",
        "    tmp_test = X_testA[:,:,i].flatten()\n",
        "    mean = np.mean(tmp_train)\n",
        "    std = np.std(tmp_train)\n",
        "    X_trainA[:,:,i] = np.reshape((tmp_train - mean)/std, (X_trainA.shape[0], X_trainA.shape[1]))\n",
        "    X_testA[:,:,i] =  np.reshape((tmp_test - mean)/std, (X_testA.shape[0], X_testA.shape[1]))\n",
        "\n",
        "for i in range(Xb_trainA.shape[-1]):\n",
        "    tmp_train = Xb_trainA[:,:,i].flatten()\n",
        "    tmp_test = Xb_testA[:,:,i].flatten()\n",
        "    mean = np.mean(tmp_train)\n",
        "    std = np.std(tmp_train)\n",
        "    Xb_trainA[:,:,i] = np.reshape((tmp_train - mean)/std, (Xb_trainA.shape[0], Xb_trainA.shape[1]))\n",
        "    Xb_testA[:,:,i] =  np.reshape((tmp_test - mean)/std, (Xb_testA.shape[0], Xb_testA.shape[1]))\n",
        "\n",
        "\n",
        "# manual aug part\n",
        "if manual_augment:\n",
        "    for i in range(X_trainM.shape[-1]):\n",
        "        tmp_train = X_trainM[:,:,i].flatten()\n",
        "        tmp_test = X_testM[:,:,i].flatten()\n",
        "        mean = np.mean(tmp_train)\n",
        "        std = np.std(tmp_train)\n",
        "        X_trainM[:,:,i] = np.reshape((tmp_train - mean)/std, (X_trainM.shape[0], X_trainM.shape[1]))\n",
        "        X_testM[:,:,i] =  np.reshape((tmp_test - mean)/std, (X_testM.shape[0], X_testM.shape[1]))\n",
        "\n",
        "    for i in range(Xb_trainM.shape[-1]):\n",
        "        tmp_train = Xb_trainM[:,:,i].flatten()\n",
        "        tmp_test = Xb_testM[:,:,i].flatten()\n",
        "        mean = np.mean(tmp_train)\n",
        "        std = np.std(tmp_train)\n",
        "        Xb_trainM[:,:,i] = np.reshape((tmp_train - mean)/std, (Xb_trainM.shape[0], Xb_trainM.shape[1]))\n",
        "        Xb_testM[:,:,i] =  np.reshape((tmp_test - mean)/std, (Xb_testM.shape[0], Xb_testM.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj3CHzJCMbZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# not augmented part\n",
        "name = 'dataset/ARS-train-test-{}-framed-norm.h5'\n",
        "with h5py.File(name.format('sensor'),'w') as h5f:\n",
        "    h5f.create_dataset('X_train', data=X_train)\n",
        "    h5f.create_dataset('X_test',  data=X_test)\n",
        "    h5f.create_dataset('Y_train', data=Y_train)\n",
        "    h5f.create_dataset('Y_test',  data=Y_test)\n",
        "\n",
        "with h5py.File(name.format('body'),'w') as h5f:\n",
        "    h5f.create_dataset('X_train', data=Xb_train)\n",
        "    h5f.create_dataset('X_test',  data=Xb_test)\n",
        "    h5f.create_dataset('Y_train', data=Yb_train)\n",
        "    h5f.create_dataset('Y_test',  data=Yb_test)\n",
        "\n",
        "\n",
        "# ADASYN part\n",
        "if augment_only_train:\n",
        "    name = 'dataset/ARS-train-test-{}-framed-aug-onlytrain-norm.h5'\n",
        "else:\n",
        "    name = 'dataset/ARS-train-test-{}-framed-aug-norm.h5'\n",
        "\n",
        "with h5py.File(name.format('sensor'),'w') as h5f:\n",
        "    h5f.create_dataset('X_train', data=X_trainA)\n",
        "    h5f.create_dataset('X_test',  data=X_testA)\n",
        "    h5f.create_dataset('Y_train', data=Y_trainA)\n",
        "    h5f.create_dataset('Y_test',  data=Y_testA)\n",
        "\n",
        "with h5py.File(name.format('body'),'w') as h5f:\n",
        "    h5f.create_dataset('X_train', data=Xb_trainA)\n",
        "    h5f.create_dataset('X_test',  data=Xb_testA)\n",
        "    h5f.create_dataset('Y_train', data=Yb_trainA)\n",
        "    h5f.create_dataset('Y_test',  data=Yb_testA)\n",
        "\n",
        "\n",
        "# Manual part\n",
        "if manual_augment:\n",
        "    if augment_only_train:\n",
        "        name = 'dataset/ARS-train-test-{}-framed-aug-onlytrain'\n",
        "    else:\n",
        "        name = 'dataset/ARS-train-test-{}-framed-aug'\n",
        "    if manual_augment and rotation:    name += '-rot'\n",
        "    if manual_augment and permutation: name += '-per'\n",
        "    name += '-norm.h5'\n",
        "\n",
        "    with h5py.File(name.format('sensor'),'w') as h5f:\n",
        "        h5f.create_dataset('X_train', data=X_trainM)\n",
        "        h5f.create_dataset('X_test',  data=X_testM)\n",
        "        h5f.create_dataset('Y_train', data=Y_trainM)\n",
        "        h5f.create_dataset('Y_test',  data=Y_testM)\n",
        "\n",
        "    with h5py.File(name.format('body'),'w') as h5f:\n",
        "        h5f.create_dataset('X_train', data=Xb_trainM)\n",
        "        h5f.create_dataset('X_test',  data=Xb_testM)\n",
        "        h5f.create_dataset('Y_train', data=Yb_trainM)\n",
        "        h5f.create_dataset('Y_test',  data=Yb_testM)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XpW5WzsQodc",
        "colab_type": "text"
      },
      "source": [
        "Checks: training set mean and std should be 0 and 1 respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqjGncLWQplM",
        "colab_type": "code",
        "outputId": "4619df15-1b46-4718-f620-49340aa093b4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1563284424127,
          "user_tz": -120,
          "elapsed": 339578,
          "user": {
            "displayName": "Filippo Rigotto",
            "photoUrl": "https://lh5.googleusercontent.com/-QEsn5Mr15CI/AAAAAAAAAAI/AAAAAAAAAFI/FgAME8VxJl8/s64/photo.jpg",
            "userId": "00487598020659430024"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# not augmented part\n",
        "for i in range(X_train.shape[-1]):\n",
        "    tmp_train = X_train[:,:,i].flatten()\n",
        "    print(f'{np.mean(tmp_train)}    \\t{np.std(tmp_train)}')\n",
        "\n",
        "print()\n",
        "for i in range(Xb_train.shape[-1]):\n",
        "    tmp_train = Xb_train[:,:,i].flatten()\n",
        "    print(f'{np.mean(tmp_train)}    \\t{np.std(tmp_train)}')\n",
        "\n",
        "\n",
        "# ADASYN aug part\n",
        "print('\\n')\n",
        "for i in range(X_trainA.shape[-1]):\n",
        "    tmp_train = X_trainA[:,:,i].flatten()\n",
        "    print(f'{np.mean(tmp_train)}    \\t{np.std(tmp_train)}')\n",
        "\n",
        "print()\n",
        "for i in range(Xb_trainA.shape[-1]):\n",
        "    tmp_train = Xb_trainA[:,:,i].flatten()\n",
        "    print(f'{np.mean(tmp_train)}    \\t{np.std(tmp_train)}')\n",
        "\n",
        "\n",
        "# manual aug part\n",
        "if manual_augment:\n",
        "    print('\\n')\n",
        "    for i in range(X_trainM.shape[-1]):\n",
        "        tmp_train = X_trainM[:,:,i].flatten()\n",
        "        print(f'{np.mean(tmp_train)}    \\t{np.std(tmp_train)}')\n",
        "\n",
        "    print()\n",
        "    for i in range(Xb_trainM.shape[-1]):\n",
        "        tmp_train = Xb_trainM[:,:,i].flatten()\n",
        "        print(f'{np.mean(tmp_train)}    \\t{np.std(tmp_train)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.901223489982452e-16    \t1.0000000000000002\n",
            "5.649741111249983e-17    \t1.0000000000000002\n",
            "1.6824760114934058e-17    \t1.0000000000000007\n",
            "-8.973575820877974e-19    \t0.9999999999999992\n",
            "5.667521571080825e-19    \t1.0000000000000004\n",
            "-2.2061661174486682e-17    \t1.0\n",
            "5.898667548881768e-16    \t1.0000000000000002\n",
            "2.0136370758428343e-17    \t0.9999999999999996\n",
            "-1.6002413847757623e-17    \t1.0000000000000002\n",
            "\n",
            "5.29385409494829e-18    \t0.9999999999999994\n",
            "-3.8269661589038415e-18    \t1.0000000000000004\n",
            "7.6608917009133485e-16    \t0.9999999999999997\n",
            "-6.9038191686940444e-18    \t1.0000000000000002\n",
            "-4.4728969261961415e-18    \t1.0000000000000002\n",
            "-1.1493400362530085e-17    \t0.9999999999999996\n",
            "-9.59078003275607e-16    \t1.000000000000001\n",
            "1.0157087678368381e-17    \t1.0\n",
            "7.09240317077491e-16    \t0.9999999999999998\n",
            "\n",
            "\n",
            "9.371235198630694e-16    \t0.9999999999999992\n",
            "1.7996885155120678e-17    \t1.0\n",
            "-9.615478640021618e-17    \t0.9999999999999999\n",
            "-1.1569426171149005e-18    \t1.0000000000000004\n",
            "4.306397519261019e-18    \t1.0\n",
            "-4.164993421613642e-17    \t1.0000000000000002\n",
            "-8.324844876040107e-16    \t0.9999999999999994\n",
            "-1.3369114686661074e-17    \t1.0000000000000004\n",
            "-7.661531108894231e-17    \t0.9999999999999993\n",
            "\n",
            "2.4303866888892315e-18    \t0.9999999999999997\n",
            "-5.596285138889678e-18    \t0.9999999999999996\n",
            "2.1480141301669694e-16    \t0.9999999999999999\n",
            "3.1978772222226733e-19    \t1.0000000000000004\n",
            "-1.3047339066668506e-17    \t0.9999999999999999\n",
            "-1.6756876644446808e-17    \t1.0\n",
            "-2.989375627333755e-16    \t0.9999999999999999\n",
            "5.6922214555563585e-18    \t1.0000000000000007\n",
            "-7.268135350667691e-16    \t0.9999999999999993\n",
            "\n",
            "\n",
            "1.3368836739972186e-16    \t0.9999999999999999\n",
            "4.673946049850719e-17    \t0.9999999999999998\n",
            "8.007912298331211e-17    \t1.0000000000000002\n",
            "5.243311810913057e-18    \t1.0000000000000004\n",
            "6.606412043964841e-18    \t1.0\n",
            "-7.197490906084641e-18    \t1.0\n",
            "1.5461014655197863e-15    \t0.9999999999999997\n",
            "2.206694418580587e-17    \t1.0000000000000002\n",
            "2.119842014350739e-17    \t1.0000000000000004\n",
            "\n",
            "-1.7732365863594003e-18    \t0.9999999999999993\n",
            "-2.6176349608162578e-18    \t1.0\n",
            "-5.612595366675522e-16    \t1.0\n",
            "4.1817824258815793e-19    \t1.0000000000000002\n",
            "-1.1741158349590588e-18    \t1.0000000000000004\n",
            "-8.186643287591245e-18    \t0.9999999999999997\n",
            "2.07159067866749e-17    \t1.0000000000000002\n",
            "4.149614868759413e-18    \t1.0\n",
            "9.885733654784053e-16    \t1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
