% arara: pdflatex
% arara: bibtex
% arara: pdflatex
% arara: pdflatex
\documentclass[journal,10pt,twoside]{IEEEtran}

%\usepackage{algorithm}
%\usepackage{algorithmicx}
%\usepackage{algpseudocode}
\usepackage[utf8]{inputenc}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[T1]{fontenc}
\usepackage{microtype}
%\usepackage{mathtools}
\usepackage[dvipsnames]{xcolor}
\usepackage{graphicx}
\usepackage[tablename=Tab.]{caption}
\usepackage{subcaption}
\usepackage{booktabs}
%\usepackage{import}
\usepackage{multirow}
\usepackage{cite}
\usepackage[export]{adjustbox}
\usepackage{breqn}
%\usepackage{mathrsfs}
\usepackage{acronym}
\usepackage[keeplastbox]{flushend}
\usepackage{setspace}
\usepackage{bm}
\usepackage{stackengine}

\usepackage{smartdiagram}
\usepackage{tikz}
\usesmartdiagramlibrary{additions}

\usepackage{hyperref}
\definecolor{azure}     {rgb}{0,0.5,1}
\definecolor{dkpowder}  {rgb}{0,0.2,0.7}
\definecolor{deepred}   {rgb}{0.7,0,0}
\definecolor{deepblue}  {rgb}{0,0,0.7}
\definecolor{deepgreen} {rgb}{0,0.5,0}
\definecolor{deeporange}{rgb}{0.91, 0.41, 0.17}
\hypersetup{%
    pdfpagemode  = {UseOutlines},
    bookmarksopen,
    pdfstartview = {FitH},
    colorlinks,
    linkcolor = {dkpowder},
    citecolor = {dkpowder},
    urlcolor  = {dkpowder},
}

%\addto\extrasenglish{%
%  \renewcommand{\sectionautorefname}{Section}%
%  \renewcommand{\subsectionautorefname}{Subsection}%
%}

\usepackage{listings}
\input{listings-def}

\renewcommand{\thetable}{\arabic{table}}
\renewcommand{\thesubtable}{\alph{subtable}}

\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\def\delequal{\mathrel{\ensurestackMath{\stackon[1pt]{=}{\scriptscriptstyle\Delta}}}}

\graphicspath{{images/}}
\setlength{\belowcaptionskip}{0mm}
\setlength{\textfloatsep}{7pt}

\newcommand{\eq}[1]{Eq.~\eqref{#1}}
\newcommand{\fig}[1]{Fig.~\ref{#1}}
\newcommand{\tab}[1]{Tab.~\ref{#1}}
\newcommand{\secref}[1]{Section~\ref{#1}}

\newcommand\MR[1]{\textcolor{blue}{#1}}
\newcommand\red[1]{\textcolor{red}{#1}}
\newcommand\comment[1]{\textcolor{ForestGreen}{[#1]}}

%\renewcommand{\baselinestretch}{0.98}
%\renewcommand{\bottomfraction}{0.8}
%\setlength{\abovecaptionskip}{0pt}
\setlength{\columnsep}{0.15in}

% fix for when no cite is in document but want bib to be shown
\makeatletter
\def\endthebibliography{%
  \def\@noitemerr{\@latex@warning{Empty `thebibliography' environment}}%
  \endlist}
\makeatother

% label colors
\definecolor{label-running} {RGB}{ 31,119,180}
\definecolor{label-walking} {RGB}{255,127, 14}
\definecolor{label-jumping} {RGB}{ 44,160, 44}
\definecolor{label-standing}{RGB}{148,103,189}
\definecolor{label-sitting} {RGB}{140, 86, 75}
\definecolor{label-lying}   {RGB}{127,127,127}
\definecolor{label-falling} {RGB}{188,189, 34}
\definecolor{label-transit} {RGB}{ 23,190,207}

% pass the color to draw the box
\newcommand{\labelbox}[1]{%
    \raisebox{1.6pt}{\fcolorbox{black}{#1}{\rule[2.5pt]{5pt}{0pt}}}
}

% \IEEEoverridecommandlockouts\IEEEpubid{\makebox[\columnwidth]{PUT COPYRIGHT NOTICE HERE \hfill} \hspace{\columnsep}\makebox[\columnwidth]{ }}
\frenchspacing
%\IEEEoverridecommandlockouts

%\title{Going deep into Human Activity Recognition}
%\author{Elia Bonetto, Filippo Rigotto
%\thanks{All authors are with the Department of Information Engineering, University of Padova, Italy. Email: \{bonettoe, rigottof\}@dei.unipd.it}}

\title{Going deep into Human Activity Recognition}
\author{%
    \IEEEauthorblockN{Elia Bonetto and Filippo Rigotto}

    \IEEEauthorblockA{Department of Information Engineering, University of Padova -- Via Gradenigo, 6/b, 35131 Padova, Italy\\ %Email:
        {\tt\{eliabntt94,rigotto.filippo\}@gmail.com}}
}
\markboth{Human Data Analytics, Spring 2019}{Bonetto \& Rigotto: Going deep into Human Activity Recognition}
\IEEEpubid{\raisebox{-1.2pt}{\includegraphics[height=7.5pt]{images/by-sa}} \copyright~2019 The authors. Licensed under \href{https://creativecommons.org/licenses/by-sa/4.0/deed.en}{Creative Commons Attribution -- ShareAlike 4.0}}

\begin{document}

\maketitle
%\thispagestyle{plain} % forced page numbers. TO DELETE before delivery
%\pagestyle{plain} % forced page numbers. TO DELETE before delivery

\begin{abstract}
In latest years, thanks to the increased number of smartphones and wearable devices integrating IMUs, Human Activity Recognition (HAR) has become a key research topic in monitored and assisted living either for medical or tracking reasons.
First attempts provided manual feature crafting, followed by analysis done either with deep neural networks or other approaches like Hidden Markov models.
More recently instead, direct analysis on raw signals has been attempted.
Here we continue this trend by exploring some possible approaches with convolutional and recurrent neural networks and look over automatic feature extraction techniques, such as autoencoders.
Most of the datasets in this field are highly imbalanced and some classes lack of enough data.
To face this, we propose two augmentation techniques for rebalancing.
Finally, we introduce new ways and metrics to select the best learning epoch to address overfitting and get the best learning results overall.
Our tests confirm that augmenting the initial dataset is worth the effort, and we achieve performance that surpass what is declared for it.
Moreover, we discovered that working with raw signals in the sensor reference frame is better than working with their transformation to the body frame.
As for encoded data by means of autoencoders, we could not find any performance improvement: in some cases, worse results are obtained.
\end{abstract}

\begin{IEEEkeywords}
Activity recognition, inertial sensors, machine learning, neural networks, autoencoders, deep classification
\end{IEEEkeywords}

\input{intro}
\input{related}
\input{model}
\input{results}
\input{conclusions}

%\nocite{*} % comment to see only cited papers in bib
\bibliographystyle{IEEEtran}
\bibliography{biblio}
\end{document}
